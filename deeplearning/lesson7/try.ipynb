{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] Не найден указанный модуль. Error loading \"C:\\Users\\Vica\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#!g1.1\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MNIST\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:141\u001B[0m\n\u001B[0;32m    139\u001B[0m                 err \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mWinError(ctypes\u001B[38;5;241m.\u001B[39mget_last_error())\n\u001B[0;32m    140\u001B[0m                 err\u001B[38;5;241m.\u001B[39mstrerror \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Error loading \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or one of its dependencies.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 141\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    143\u001B[0m     kernel32\u001B[38;5;241m.\u001B[39mSetErrorMode(prev_error_mode)\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_preload_cuda_deps\u001B[39m(lib_folder, lib_name):\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 126] Не найден указанный модуль. Error loading \"C:\\Users\\Vica\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T10:56:36.779096200Z",
     "start_time": "2024-05-20T10:56:36.170405800Z"
    }
   },
   "id": "a0ce9d6024b2b26a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "mnist_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize((64, 64)),\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = MNIST('mnist', train=True, transform=mnist_transforms, download=True)\n",
    "valid_dataset = MNIST('mnist', train=False, transform=mnist_transforms, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T13:02:23.434726Z",
     "start_time": "2024-04-15T13:02:23.387729500Z"
    }
   },
   "id": "6dafa805c2cb0079"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучите автоэнкодер на датасете MNIST, постарайтесь сделать его с размером эмбеддинга не больше 128. Сгенерируйте эмбеддинги для тысячи объектов из обучающей выборки (как в семинаре), обучите на этих эмбеддингах Случайный лес. Добейтесь Accuracy больше 90%.\n",
    "\n",
    "Сделайте эмбеддинги для 1000 объектов из обучающей выборки, тензор с ними должен иметь размерность (1000,N), где N≤128. Мы обучим на этом тензоре Случайный лес из библиотеки scikit-learn, а именно RandomForestClassifier(random_state=0). После чего проверим качество на ваших эмбеддингах для тестовой выборки, сдайте их тоже. Тензор с эмбеддингами для тестовой выборки должен иметь размерность (10000,N). Accuracy нашего обученного случайного леса должна быть больше 90% на тестовых эмбеддингах.\n",
    "\n",
    "Чтобы корректно сдать все эмбеддинги воспользуйтесь этой функцией:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cc86fe87ee92d7c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def train(model):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for x, _ in tqdm(train_loader, desc='Train'):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, x)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    return train_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:48:58.858275700Z",
     "start_time": "2024-04-15T12:48:58.851266100Z"
    }
   },
   "id": "49d2093eff0ac15a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, _ in tqdm(loader, desc='Evaluation'):\n",
    "        x = x.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, x)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "\n",
    "    return total_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:00.315790900Z",
     "start_time": "2024-04-15T12:49:00.309277700Z"
    }
   },
   "id": "1b1efef28d6127a8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def plot_stats(\n",
    "        train_loss: list[float],\n",
    "        valid_loss: list[float],\n",
    "        title: str\n",
    "):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:01.596464Z",
     "start_time": "2024-04-15T12:49:01.589947100Z"
    }
   },
   "id": "a5816f0e4ff8180e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def visualize(model, xs):\n",
    "    model.eval()\n",
    "\n",
    "    to_pil = T.ToPILImage()\n",
    "\n",
    "    outputs = model(xs.to(device)).cpu()\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "\n",
    "    plt.imshow(\n",
    "        to_pil(\n",
    "            torch.cat(\n",
    "                (\n",
    "                    make_grid(xs[:10], nrow=10, pad_value=1),\n",
    "                    make_grid(outputs[:10], nrow=10, pad_value=1)\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:02.546407600Z",
     "start_time": "2024-04-15T12:49:02.524364200Z"
    }
   },
   "id": "41e2b2ca01b9340f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def whole_train_valid_cycle(model, num_epochs, title):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model)\n",
    "        valid_loss = evaluate(model, valid_loader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        visualize(model, next(iter(valid_loader))[0])\n",
    "\n",
    "        plot_stats(\n",
    "            train_loss_history, valid_loss_history,\n",
    "            title\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:03.387065200Z",
     "start_time": "2024-04-15T12:49:03.383280300Z"
    }
   },
   "id": "af88e14a96d8b58e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, upsample: bool = False):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DenoisingBlock(Block):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, upsample: bool = False):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, upsample)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "\n",
    "        if self.training:\n",
    "            x = x + torch.randn_like(x) * 0.05\n",
    "\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, base_block: nn.Module = Block, base_size: int = 32, num_blocks: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_size = base_size\n",
    "\n",
    "        # encoder creation\n",
    "\n",
    "        encoder_blocks = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            encoder_blocks.append(\n",
    "                base_block(\n",
    "                    in_channels=base_size if i else in_channels,\n",
    "                    out_channels=base_size,\n",
    "                    kernel_size=3,\n",
    "                    stride=2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        encoder_blocks.append(\n",
    "            base_block(\n",
    "                in_channels=base_size,\n",
    "                out_channels=base_size,\n",
    "                kernel_size=3\n",
    "            ).conv\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_blocks)  # N -> N // (2 ** num_blocks)\n",
    "\n",
    "        # decoder creation\n",
    "\n",
    "        decoder_blocks = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            decoder_blocks.append(\n",
    "                base_block(\n",
    "                    in_channels=base_size,\n",
    "                    out_channels=base_size,\n",
    "                    kernel_size=3,\n",
    "                    upsample=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoder_blocks.append(\n",
    "            base_block(\n",
    "                in_channels=base_size,\n",
    "                out_channels=in_channels,\n",
    "                kernel_size=3\n",
    "            ).conv\n",
    "        )\n",
    "        decoder_blocks.append(nn.Sigmoid())\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_blocks)  # N // (2 ** num_blocks) -> N\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [bs, base_size, N // (2 ** num_blocks), N // (2 ** num_blocks)]\n",
    "        x = self.decoder(x)\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def encode(self, x):\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        return self.flatten(self.encoder(x)) # output.shape = [bs, base_size * N ** 2 / (2 ** num_blocks) ** 2]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def decode(self, x):\n",
    "        # x.shape = [bs, base_size * N ** 2 / (2 ** num_blocks) ** 2]\n",
    "        latent_size = int(math.sqrt(x.shape[1] // self.base_size))\n",
    "\n",
    "        return self.decoder(x.view(-1, self.base_size, latent_size, latent_size))  # output.shape = [bs, in_channels, N, N]\n",
    "\n",
    "\n",
    "class DenoisingAutoEncoder(AutoEncoder):\n",
    "    def __init__(self, in_channels: int, base_block: nn.Module = DenoisingBlock, base_size: int = 32, num_blocks: int = 4):\n",
    "        super().__init__(in_channels, base_block, base_size, num_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x = torch.clip(x + torch.randn_like(x) * 0.1, min=0, max=1)\n",
    "\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [bs, base_size, N // (2 ** num_blocks), N // (2 ** num_blocks)]\n",
    "        x = self.decoder(x)\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:04.596952900Z",
     "start_time": "2024-04-15T12:49:04.594943Z"
    }
   },
   "id": "b3b68c3e466f8124"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:15.062896300Z",
     "start_time": "2024-04-15T12:49:13.926260100Z"
    }
   },
   "id": "2b7fe704454b847b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = autoencoder = DenoisingAutoEncoder(in_channels=1, base_size=128, num_blocks=4).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:49:17.469733300Z",
     "start_time": "2024-04-15T12:49:16.888047900Z"
    }
   },
   "id": "edd362a2b1f152c7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      4\u001B[0m     img, _ \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m----> 5\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      7\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(img)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        img, _ = data\n",
    "        img = img.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = loss_fn(output, img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('hi')\n",
    "\n",
    "embeddings = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        img, target = data\n",
    "        img = img.to(device)\n",
    "        embedding = model.encode(img)\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "        targets.append(target.numpy())\n",
    "\n",
    "embeddings = np.concatenate(embeddings)\n",
    "targets = np.concatenate(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:56:39.014862400Z",
     "start_time": "2024-04-15T12:49:20.426301200Z"
    }
   },
   "id": "eea3d6b7610bbf15"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 64 at dim 1 (got 32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m         train_embeddings\u001B[38;5;241m.\u001B[39mappend(embedding)\n\u001B[0;32m     20\u001B[0m         train_targets\u001B[38;5;241m.\u001B[39mappend(target\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m---> 22\u001B[0m train_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_embeddings\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m128\u001B[39m)\n\u001B[0;32m     23\u001B[0m train_targets \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(train_targets)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     25\u001B[0m train_embeddings \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(train_embeddings, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: expected sequence of length 64 at dim 1 (got 32)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "autoencoder = DenoisingAutoEncoder(in_channels=1, base_size=128, num_blocks=4)\n",
    "autoencoder.to(device)\n",
    "autoencoder.eval()  # переводим модель в режим оценки (не тренировки)\n",
    "\n",
    "# Получаем эмбеддинги для обучающей выборки\n",
    "train_embeddings = []\n",
    "train_targets = []\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        img, target = data\n",
    "        img = img.to(device)\n",
    "        embedding = autoencoder.encode(img).cpu().numpy()\n",
    "        train_embeddings.append(embedding)\n",
    "        train_targets.append(target.numpy())\n",
    "\n",
    "train_embeddings = torch.tensor(train_embeddings).view(-1, 128)\n",
    "train_targets = torch.tensor(train_targets).view(-1)\n",
    "\n",
    "train_embeddings = torch.cat(train_embeddings, dim=0)\n",
    "train_targets = torch.cat(train_targets, dim=0)\n",
    "\n",
    "# Обучение Random Forest на эмбеддингах обучающей выборки\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(train_embeddings[:1000], train_targets[:1000])\n",
    "\n",
    "\n",
    "test_embeddings = []\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        img, target = data\n",
    "        img = img.to(device)\n",
    "        embedding = autoencoder.encode(img).cpu().numpy()\n",
    "        test_embeddings.append(embedding)\n",
    "        test_targets.append(target.numpy())\n",
    "\n",
    "test_embeddings = torch.tensor(test_embeddings).view(-1, 128)  # Преобразуем в тензор и выравниваем размерность\n",
    "test_targets = torch.tensor(test_targets).view(-1)  # Преобразуем в тензор и выравниваем размерность\n",
    "\n",
    "test_preds = clf.predict(test_embeddings)\n",
    "accuracy = accuracy_score(test_targets, test_preds)\n",
    "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T13:04:31.220998600Z",
     "start_time": "2024-04-15T13:04:13.475747100Z"
    }
   },
   "id": "54e9c6f555faffa3"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15054bd66e81c59a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T07:28:26.956868400Z",
     "start_time": "2024-04-15T07:28:23.601115900Z"
    }
   },
   "id": "9572d3b2506df9c0"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(embeddings[:1000], targets[:1000])\n",
    "test_embeddings = []\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        img, target = data\n",
    "        img = img.to(device)\n",
    "        embedding = autoencoder.encode(img)\n",
    "        test_embeddings.append(embedding.cpu().numpy())\n",
    "        test_targets.append(target.numpy())\n",
    "\n",
    "test_embeddings = np.concatenate(test_embeddings)\n",
    "test_targets = np.concatenate(test_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T07:28:34.867266900Z",
     "start_time": "2024-04-15T07:28:27.589650300Z"
    }
   },
   "id": "53260534871bc859"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 91.91%\n"
     ]
    }
   ],
   "source": [
    "test_preds = clf.predict(test_embeddings)\n",
    "accuracy = accuracy_score(test_targets, test_preds)\n",
    "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T07:28:35.175412300Z",
     "start_time": "2024-04-15T07:28:34.864278100Z"
    }
   },
   "id": "4207bf06be100995"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "60000"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T08:31:13.661981300Z",
     "start_time": "2024-04-15T08:31:13.635289600Z"
    }
   },
   "id": "8c24cf8510aedcf1"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:53.195420700Z",
     "start_time": "2024-04-15T08:21:53.172422300Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_embeddings(x_train, y_train, x_valid, y_valid):\n",
    "    assert x_train.shape[0] == 1000\n",
    "    assert x_valid.shape[0] == 10000\n",
    "    \n",
    "    assert y_train.shape[0] == 1000\n",
    "    assert y_valid.shape[0] == 10000\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            'x_train': x_train,\n",
    "            'y_train': y_train,\n",
    "            'x_valid': x_valid,\n",
    "            'y_valid': y_valid\n",
    "        },\n",
    "        'embeddings3.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "save_embeddings(embeddings[:1000], targets[:1000], test_embeddings, test_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:54.802136900Z",
     "start_time": "2024-04-15T08:21:53.760970600Z"
    }
   },
   "id": "88bd4656cd85efd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "28ccd54058cecd6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
